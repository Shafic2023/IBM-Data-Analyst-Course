{"cells":[{"cell_type":"markdown","id":"a1477b8f-a8d7-47b1-8757-56444dad8a91","metadata":{},"outputs":[],"source":["\u003ccenter\u003e\n","    \u003cimg src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0101EN-SkillsNetwork/IDSNlogo.png\" width=\"300\" alt=\"cognitiveclass.ai logo\"\u003e\n","\u003c/center\u003e\n"]},{"cell_type":"markdown","id":"76a04e25-ae4f-4d78-b342-2a0197511ea6","metadata":{},"outputs":[],"source":["# **Web Scraping Lab**\n"]},{"cell_type":"markdown","id":"93c3de1d-e860-4592-9dee-59a14167989d","metadata":{},"outputs":[],"source":["Estimated time needed: **40** minutes\n"]},{"cell_type":"markdown","id":"5dae311e-39e9-4e67-9e9a-054c21910f7e","metadata":{},"outputs":[],"source":["## Objectives\n"]},{"cell_type":"markdown","id":"31d9f62a-0252-4190-82ff-514d5d48243b","metadata":{},"outputs":[],"source":["After completing this lab you will be:\n","\n","*   Familiar with the basics of the `BeautifulSoup` Python library\n","*   Be able to scrape webpages for data and filter the data\n"]},{"cell_type":"markdown","id":"e95300a2-3276-4d2c-a74f-530fe615b0d8","metadata":{},"outputs":[],"source":["\u003ch2\u003eTable of Contents\u003c/h2\u003e\n","\u003cdiv class=\"alert alert-block alert-info\" style=\"margin-top: 20px\"\u003e\n","    \u003cul\u003e\n","        \u003cli\u003e\n","            \u003ca href=\"#Beautiful-Soup-Object\"\u003eBeautiful Soup Object\u003c/a\u003e\n","            \u003cul\u003e\n","                \u003cli\u003e\u003ca href=\"#Tags\"\u003eTags\u003c/a\u003e\u003c/li\u003e\n","                \u003cli\u003e\u003ca href=\"#Children,-Parents,-and-Siblings\"\u003eChildren, Parents, and Siblings\u003c/a\u003e\u003c/li\u003e\n","                \u003cli\u003e\u003ca href=\"#HTML-Attributes\"\u003eHTML Attributes\u003c/a\u003e\u003c/li\u003e\n","                \u003cli\u003e\u003ca href=\"#Navigable-String\"\u003eNavigable String\u003c/a\u003e\u003c/li\u003e\n","            \u003c/ul\u003e\n","        \u003c/li\u003e\n","     \u003c/ul\u003e\n","    \u003cul\u003e\n","        \u003cli\u003e\n","            \u003ca href=\"#Filter\"\u003eFilter\u003c/a\u003e\n","            \u003cul\u003e\n","                \u003cli\u003e\u003ca href=\"#find_All\"\u003efind_All\u003c/a\u003e\u003c/li\u003e\n","                \u003cli\u003e\u003ca href=\"#find\"\u003efind\u003c/a\u003e\u003c/li\u003e\n","            \u003c/ul\u003e\n","        \u003c/li\u003e\n","     \u003c/ul\u003e\n","     \u003cul\u003e\n","        \u003cli\u003e\n","            \u003ca href=\"#Downloading-And-Scraping-The-Contents-Of-A-Web-Page\"\u003eDownloading And Scraping The Contents Of A Web Page\u003c/a\u003e\u003c/li\u003e\n","         \u003cli\u003e \u003ca href=\"#Scraping-tables-from-a-Web-page-using-Pandas\"\u003eScraping tables from a Web page using Pandas\u003c/a\u003e\u003c/li\u003e\n","    \u003c/ul\u003e\n","\n","\u003c/div\u003e\n","\n","\u003chr\u003e\n"]},{"cell_type":"markdown","id":"6c827db0-2d8f-4957-83bb-69f9935b8f18","metadata":{},"outputs":[],"source":["For this lab, we are going to be using Python and several Python libraries. Some of these libraries might be installed in your lab environment or in SN Labs. Others may need to be installed by you. The cells below will install these libraries when executed.\n"]},{"cell_type":"code","id":"0428d96e-71b6-45df-8bbd-842728086594","metadata":{},"outputs":[],"source":["!pip install html5lib"]},{"cell_type":"markdown","id":"1f24c9f9-86d2-428c-ab81-bf54f083f9ca","metadata":{},"outputs":[],"source":["**Note:- After running the above code cell, restart the kernel and don't run the above code cell after restarting the kernel.**\n"]},{"cell_type":"code","id":"c3783715-8016-402d-bd37-ae95ea7fa5a3","metadata":{},"outputs":[],"source":["!pip install bs4\n#!pip install requests"]},{"cell_type":"markdown","id":"d4d5da7f-e04d-49da-a6a2-1d2406e2426c","metadata":{},"outputs":[],"source":["Import the required modules and functions\n"]},{"cell_type":"code","id":"c91808fa-4e9a-43d8-8786-2b55e504fe83","metadata":{},"outputs":[],"source":["from bs4 import BeautifulSoup # this module helps in web scrapping.\nimport requests  # this module helps us to download a web page"]},{"cell_type":"markdown","id":"cd501e03-9401-4e9b-955e-ab77abadb5b3","metadata":{},"outputs":[],"source":["## Beautiful Soup Object\n"]},{"cell_type":"markdown","id":"206ee994-c30d-489b-b23f-6594696d69c4","metadata":{},"outputs":[],"source":["Beautiful Soup is a Python library for pulling data out of HTML and XML files, we will focus on HTML files. This is accomplished by representing the HTML as a set of objects with methods used to parse the HTML.  We can navigate the HTML as a tree, and/or filter out what we are looking for.\n","\n","Consider the following HTML:\n"]},{"cell_type":"code","id":"7e810b0d-614d-433e-891e-957a69b69c78","metadata":{},"outputs":[],"source":["%%html\n\u003c!DOCTYPE html\u003e\n\u003chtml\u003e\n\u003chead\u003e\n\u003ctitle\u003ePage Title\u003c/title\u003e\n\u003c/head\u003e\n\u003cbody\u003e\n\u003ch3\u003e\u003cb id='boldest'\u003eLebron James\u003c/b\u003e\u003c/h3\u003e\n\u003cp\u003e Salary: $ 92,000,000 \u003c/p\u003e\n\u003ch3\u003e Stephen Curry\u003c/h3\u003e\n\u003cp\u003e Salary: $85,000, 000 \u003c/p\u003e\n\u003ch3\u003e Kevin Durant \u003c/h3\u003e\n\u003cp\u003e Salary: $73,200, 000\u003c/p\u003e\n\u003c/body\u003e\n\u003c/html\u003e"]},{"cell_type":"markdown","id":"1da3a0d5-0905-42db-842b-c69763deb13c","metadata":{},"outputs":[],"source":["We can store it as a string in the variable HTML:\n"]},{"cell_type":"code","id":"e92f7643-15ea-4f8a-8e02-bb54a81041ad","metadata":{},"outputs":[],"source":["html=\"\u003c!DOCTYPE html\u003e\u003chtml\u003e\u003chead\u003e\u003ctitle\u003ePage Title\u003c/title\u003e\u003c/head\u003e\u003cbody\u003e\u003ch3\u003e\u003cb id='boldest'\u003eLebron James\u003c/b\u003e\u003c/h3\u003e\u003cp\u003e Salary: $ 92,000,000 \u003c/p\u003e\u003ch3\u003e Stephen Curry\u003c/h3\u003e\u003cp\u003e Salary: $85,000, 000 \u003c/p\u003e\u003ch3\u003e Kevin Durant \u003c/h3\u003e\u003cp\u003e Salary: $73,200, 000\u003c/p\u003e\u003c/body\u003e\u003c/html\u003e\""]},{"cell_type":"markdown","id":"de177f38-15f1-431c-8d11-36113ad6690f","metadata":{},"outputs":[],"source":["To parse a document, pass it into the \u003ccode\u003eBeautifulSoup\u003c/code\u003e constructor. The \u003ccode\u003eBeautifulSoup\u003c/code\u003e object represents the document as a nested data structure:\n"]},{"cell_type":"code","id":"aa18d377-2b5c-4452-bf84-b61e653f6e8b","metadata":{},"outputs":[],"source":["soup = BeautifulSoup(html, 'html5lib')"]},{"cell_type":"markdown","id":"8dc8d60e-1f03-4260-906c-2dd0484e357d","metadata":{},"outputs":[],"source":["First, the document is converted to Unicode (similar to ASCII) and HTML entities are converted to Unicode characters. Beautiful Soup transforms a complex HTML document into a complex tree of Python objects. The \u003ccode\u003eBeautifulSoup\u003c/code\u003e object can create other types of objects. In this lab, we will cover \u003ccode\u003eBeautifulSoup\u003c/code\u003e and \u003ccode\u003eTag\u003c/code\u003e objects, that for the purposes of this lab are identical. Finally, we will look at \u003ccode\u003eNavigableString\u003c/code\u003e objects.\n"]},{"cell_type":"markdown","id":"c16679d4-fa8c-42a3-a490-39c5477f6886","metadata":{},"outputs":[],"source":["We can use the method \u003ccode\u003eprettify()\u003c/code\u003e to display the HTML in the nested structure:\n"]},{"cell_type":"code","id":"a08cff02-80d3-4107-9454-b21770756ec4","metadata":{},"outputs":[],"source":["print(soup.prettify())"]},{"cell_type":"markdown","id":"78259c87-f479-4aed-a35e-6e442a1c7377","metadata":{},"outputs":[],"source":["## Tags\n"]},{"cell_type":"markdown","id":"c65fef1c-2345-4b78-a7b8-33bcc5feb312","metadata":{},"outputs":[],"source":["Let's say we want the  title of the page and the name of the top paid player. We can use the \u003ccode\u003eTag\u003c/code\u003e. The \u003ccode\u003eTag\u003c/code\u003e object corresponds to an HTML tag in the original document, for example, the tag title.\n"]},{"cell_type":"code","id":"22043cc8-2059-4512-bb30-e83f0a2ad3d0","metadata":{},"outputs":[],"source":["tag_object=soup.title\nprint(\"tag object:\",tag_object)"]},{"cell_type":"markdown","id":"bef2e51e-a5a3-452b-8c1e-bb500ffe1d65","metadata":{},"outputs":[],"source":["we can see the tag type \u003ccode\u003ebs4.element.Tag\u003c/code\u003e\n"]},{"cell_type":"code","id":"30cedc94-e258-4da8-82e1-08de13e5104b","metadata":{},"outputs":[],"source":["print(\"tag object type:\",type(tag_object))"]},{"cell_type":"markdown","id":"f125ff93-4d10-47a1-b853-cfcf593f8ff6","metadata":{},"outputs":[],"source":["If there is more than one \u003ccode\u003eTag\u003c/code\u003e with the same name, the first element with that \u003ccode\u003eTag\u003c/code\u003e name is called. This corresponds to the most paid player:\n"]},{"cell_type":"code","id":"bbbf01e9-7518-49ca-bfcd-9247f76be188","metadata":{},"outputs":[],"source":["tag_object=soup.h3\ntag_object"]},{"cell_type":"markdown","id":"c6834365-e3aa-4d59-967a-919b3eab39b8","metadata":{},"outputs":[],"source":["Enclosed in the bold attribute \u003ccode\u003eb\u003c/code\u003e, it helps to use the tree representation. We can navigate down the tree using the child attribute to get the name.\n"]},{"cell_type":"markdown","id":"a2f99c47-22f2-4d23-b44a-084797d0de61","metadata":{},"outputs":[],"source":["### Children, Parents, and Siblings\n"]},{"cell_type":"markdown","id":"95aa8115-e51c-4a70-8912-de6e45adc50c","metadata":{},"outputs":[],"source":["As stated above, the \u003ccode\u003eTag\u003c/code\u003e object is a tree of objects. We can access the child of the tag or navigate down the branch as follows:\n"]},{"cell_type":"code","id":"437cc21f-34b8-438a-b1a2-d321ddc90ddc","metadata":{},"outputs":[],"source":["tag_child =tag_object.b\ntag_child"]},{"cell_type":"markdown","id":"cb3039ad-7e29-4200-9c7f-a4bb0d491f3a","metadata":{},"outputs":[],"source":["You can access the parent with the \u003ccode\u003e parent\u003c/code\u003e.\n"]},{"cell_type":"code","id":"3577e9f0-1d58-4735-902e-4f4ec13732d0","metadata":{},"outputs":[],"source":["parent_tag=tag_child.parent\nparent_tag"]},{"cell_type":"markdown","id":"ad242a4a-06a5-4a8d-961c-099e8a2b8ae6","metadata":{},"outputs":[],"source":["this is identical to:\n"]},{"cell_type":"code","id":"ee267842-01ec-448d-9f38-4e1426001575","metadata":{},"outputs":[],"source":["tag_object"]},{"cell_type":"markdown","id":"0a5828cd-f962-48ed-8e61-a49f05f358f3","metadata":{},"outputs":[],"source":["\u003ccode\u003etag_object\u003c/code\u003e parent is the \u003ccode\u003ebody\u003c/code\u003e element.\n"]},{"cell_type":"code","id":"00755a73-02ae-483f-90ad-88d4bb82d779","metadata":{},"outputs":[],"source":["tag_object.parent"]},{"cell_type":"markdown","id":"783efde9-e42b-4262-b996-1dbb128a0533","metadata":{},"outputs":[],"source":["\u003ccode\u003etag_object\u003c/code\u003e sibling is the \u003ccode\u003eparagraph\u003c/code\u003e element.\n"]},{"cell_type":"code","id":"fc246920-2197-41cc-ae6e-80ee1d19f336","metadata":{},"outputs":[],"source":["sibling_1=tag_object.next_sibling\nsibling_1"]},{"cell_type":"markdown","id":"ad43649b-6c29-4eae-a9fd-c103bc1dba2a","metadata":{},"outputs":[],"source":["`sibling_2` is the `header` element, which is also a sibling of both `sibling_1` and `tag_object`\n"]},{"cell_type":"code","id":"68b4f9fa-3322-4296-9b77-67656346f72c","metadata":{},"outputs":[],"source":["sibling_2=sibling_1.next_sibling\nsibling_2"]},{"cell_type":"markdown","id":"2385f2cc-869e-4ee6-8de7-5aef7bd09198","metadata":{},"outputs":[],"source":["\u003ch3 id=\"first_question\"\u003eExercise: \u003ccode\u003enext_sibling\u003c/code\u003e\u003c/h3\u003e\n"]},{"cell_type":"markdown","id":"c139e030-51cd-4583-bb12-f3bc515b554a","metadata":{},"outputs":[],"source":["Use the object \u003ccode\u003esibling\\_2\u003c/code\u003e and the method \u003ccode\u003enext_sibling\u003c/code\u003e to find the salary of Stephen Curry:\n"]},{"cell_type":"code","id":"59854658-f103-474b-93af-f1ad42ce3a61","metadata":{},"outputs":[],"source":[""]},{"cell_type":"markdown","id":"6a573f0e-4c94-4687-b4ad-f935b172eac9","metadata":{},"outputs":[],"source":["\u003cdetails\u003e\u003csummary\u003eClick here for the solution\u003c/summary\u003e\n","\n","```\n","sibling_2.next_sibling\n","\n","```\n","\n","\u003c/details\u003e\n"]},{"cell_type":"markdown","id":"c42a04c3-3d8a-48d1-b182-66450f8701ff","metadata":{},"outputs":[],"source":["### HTML Attributes\n"]},{"cell_type":"markdown","id":"95545613-a8cf-4799-8384-3bd232ab59cd","metadata":{},"outputs":[],"source":["If the tag has attributes, the tag \u003ccode\u003eid=\"boldest\"\u003c/code\u003e has an attribute \u003ccode\u003eid\u003c/code\u003e whose value is \u003ccode\u003eboldest\u003c/code\u003e. You can access a tag's attributes by treating the tag like a dictionary:\n"]},{"cell_type":"code","id":"2bb697aa-ba5b-4220-ac9c-d2ea22aa8a01","metadata":{},"outputs":[],"source":["tag_child['id']"]},{"cell_type":"markdown","id":"2afb4d01-5040-4464-913a-b220b666a3c7","metadata":{},"outputs":[],"source":["You can access that dictionary directly as \u003ccode\u003eattrs\u003c/code\u003e:\n"]},{"cell_type":"code","id":"baf7f1b1-ecc3-45bf-98cb-cacc2166d542","metadata":{},"outputs":[],"source":["tag_child.attrs"]},{"cell_type":"markdown","id":"081b9bb6-e6ab-43b0-84c0-9e2542581b08","metadata":{},"outputs":[],"source":["You can also work with Multi-valued attributes. Check out \u003ca href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/?utm_medium=Exinfluencer\u0026utm_source=Exinfluencer\u0026utm_content=000026UJ\u0026utm_term=10006555\u0026utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkPY0101ENSkillsNetwork19487395-2021-01-01\"\u003e\\[1]\u003c/a\u003e for more.\n"]},{"cell_type":"markdown","id":"5bcb61d1-c63f-4f47-b975-f920ccd12e65","metadata":{},"outputs":[],"source":["We can also obtain the content of the attribute of the \u003ccode\u003etag\u003c/code\u003e using the Python \u003ccode\u003eget()\u003c/code\u003e method.\n"]},{"cell_type":"code","id":"993017b9-e3a3-4eae-8d0c-02ce3f5787d4","metadata":{},"outputs":[],"source":["tag_child.get('id')"]},{"cell_type":"markdown","id":"7166293e-6803-48a8-8163-a5892443b1ae","metadata":{},"outputs":[],"source":["### Navigable String\n"]},{"cell_type":"markdown","id":"7e630937-96f5-4359-b668-8174232993ad","metadata":{},"outputs":[],"source":["A string corresponds to a bit of text or content within a tag. Beautiful Soup uses the \u003ccode\u003eNavigableString\u003c/code\u003e class to contain this text. In our HTML we can obtain the name of the first player by extracting the string of the \u003ccode\u003eTag\u003c/code\u003e object \u003ccode\u003etag_child\u003c/code\u003e as follows:\n"]},{"cell_type":"code","id":"74a820e3-8f27-4e0f-891c-da37e63884c3","metadata":{},"outputs":[],"source":["tag_string=tag_child.string\ntag_string"]},{"cell_type":"markdown","id":"d573ea8c-6937-42ca-ac7f-c70505d200a7","metadata":{},"outputs":[],"source":["we can verify the type is Navigable String\n"]},{"cell_type":"code","id":"ca55c077-6c1c-45b8-8c9a-f81aaa95d3b1","metadata":{},"outputs":[],"source":["type(tag_string)"]},{"cell_type":"markdown","id":"03020fee-6a50-4f78-a460-934414330961","metadata":{},"outputs":[],"source":["A NavigableString is similar to a Python string or Unicode string. To be more precise, the main difference is that it also supports some \u003ccode\u003eBeautifulSoup\u003c/code\u003e features. We can convert it to string object in Python:\n"]},{"cell_type":"code","id":"cb523ce9-2522-48a5-890c-5d92f1f78240","metadata":{},"outputs":[],"source":["unicode_string = str(tag_string)\nunicode_string"]},{"cell_type":"markdown","id":"122f5c28-d2ba-49b0-94ea-d90610c44177","metadata":{},"outputs":[],"source":["## Filter\n"]},{"cell_type":"markdown","id":"d42cf065-d0ad-4124-8b94-a8fae600b0d4","metadata":{},"outputs":[],"source":["Filters allow you to find complex patterns, the simplest filter is a string. In this section we will pass a string to a different filter method and Beautiful Soup will perform a match against that exact string. Consider the following HTML of rocket launches:\n"]},{"cell_type":"code","id":"04bee9fb-1446-481b-9661-7440554d4074","metadata":{},"outputs":[],"source":["%%html\n\u003ctable\u003e\n  \u003ctr\u003e\n    \u003ctd id='flight' \u003eFlight No\u003c/td\u003e\n    \u003ctd\u003eLaunch site\u003c/td\u003e \n    \u003ctd\u003ePayload mass\u003c/td\u003e\n   \u003c/tr\u003e\n  \u003ctr\u003e \n    \u003ctd\u003e1\u003c/td\u003e\n    \u003ctd\u003e\u003ca href='https://en.wikipedia.org/wiki/Florida'\u003eFlorida\u003c/a\u003e\u003c/td\u003e\n    \u003ctd\u003e300 kg\u003c/td\u003e\n  \u003c/tr\u003e\n  \u003ctr\u003e\n    \u003ctd\u003e2\u003c/td\u003e\n    \u003ctd\u003e\u003ca href='https://en.wikipedia.org/wiki/Texas'\u003eTexas\u003c/a\u003e\u003c/td\u003e\n    \u003ctd\u003e94 kg\u003c/td\u003e\n  \u003c/tr\u003e\n  \u003ctr\u003e\n    \u003ctd\u003e3\u003c/td\u003e\n    \u003ctd\u003e\u003ca href='https://en.wikipedia.org/wiki/Florida'\u003eFlorida\u003ca\u003e \u003c/td\u003e\n    \u003ctd\u003e80 kg\u003c/td\u003e\n  \u003c/tr\u003e\n\u003c/table\u003e"]},{"cell_type":"markdown","id":"3c3a7012-5433-4ce1-a7d0-f52abbb50482","metadata":{},"outputs":[],"source":["We can store it as a string in the variable \u003ccode\u003etable\u003c/code\u003e:\n"]},{"cell_type":"code","id":"b7dac682-3e5c-458a-b0fe-fd8abe6b64b5","metadata":{},"outputs":[],"source":["table=\"\u003ctable\u003e\u003ctr\u003e\u003ctd id='flight'\u003eFlight No\u003c/td\u003e\u003ctd\u003eLaunch site\u003c/td\u003e \u003ctd\u003ePayload mass\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e \u003ctd\u003e1\u003c/td\u003e\u003ctd\u003e\u003ca href='https://en.wikipedia.org/wiki/Florida'\u003eFlorida\u003ca\u003e\u003c/td\u003e\u003ctd\u003e300 kg\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e2\u003c/td\u003e\u003ctd\u003e\u003ca href='https://en.wikipedia.org/wiki/Texas'\u003eTexas\u003c/a\u003e\u003c/td\u003e\u003ctd\u003e94 kg\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e3\u003c/td\u003e\u003ctd\u003e\u003ca href='https://en.wikipedia.org/wiki/Florida'\u003eFlorida\u003ca\u003e \u003c/td\u003e\u003ctd\u003e80 kg\u003c/td\u003e\u003c/tr\u003e\u003c/table\u003e\""]},{"cell_type":"code","id":"cf406046-5be5-4025-bf87-436eb366e21b","metadata":{},"outputs":[],"source":["table_bs = BeautifulSoup(table, 'html5lib')"]},{"cell_type":"markdown","id":"e7176649-ae82-444c-a4b7-f87d6731fb3c","metadata":{},"outputs":[],"source":["## find_All\n"]},{"cell_type":"markdown","id":"763f0eb5-4abd-48b1-8f7d-0362da7cfa27","metadata":{},"outputs":[],"source":["The \u003ccode\u003efind_all()\u003c/code\u003e method looks through a tag's descendants and retrieves all descendants that match your filters.\n","\n","\u003cp\u003e\n","The Method signature for \u003ccode\u003efind_all(name, attrs, recursive, string, limit, **kwargs)\u003cc/ode\u003e\n","\u003c/p\u003e\n"]},{"cell_type":"markdown","id":"2b1b490e-58d0-4e7e-a345-83525ba130c7","metadata":{},"outputs":[],"source":["### Name\n"]},{"cell_type":"markdown","id":"4704ef45-47f5-48ef-a2dc-a3c711e65423","metadata":{},"outputs":[],"source":["When we set the \u003ccode\u003ename\u003c/code\u003e parameter to a tag name, the method will extract all the tags with that name and its children.\n"]},{"cell_type":"code","id":"e2793cd7-9833-46a0-a3d0-7fcb3324b489","metadata":{},"outputs":[],"source":["table_rows=table_bs.find_all('tr')\ntable_rows"]},{"cell_type":"markdown","id":"3040b3c5-f69f-4a17-8f57-78248d38fd47","metadata":{},"outputs":[],"source":["The result is a Python iterable just like a list, each element is a \u003ccode\u003etag\u003c/code\u003e object:\n"]},{"cell_type":"code","id":"80ef402c-323b-4334-8052-90cfc7c3e2df","metadata":{},"outputs":[],"source":["first_row =table_rows[0]\nfirst_row"]},{"cell_type":"markdown","id":"85f7d547-ca41-4690-bac1-3fc12caed447","metadata":{},"outputs":[],"source":["The type is \u003ccode\u003etag\u003c/code\u003e\n"]},{"cell_type":"code","id":"1092f8e2-be14-49da-8e91-9d4950a0adeb","metadata":{},"outputs":[],"source":["print(type(first_row))"]},{"cell_type":"markdown","id":"d9dc1fd9-8ca1-405a-8ace-b1d78129cc0c","metadata":{},"outputs":[],"source":["we can obtain the child\n"]},{"cell_type":"code","id":"cdb0caab-eb13-4bf3-82fa-83518e8671f1","metadata":{},"outputs":[],"source":["first_row.td"]},{"cell_type":"markdown","id":"2d229567-721d-4fff-8bfc-1fdd69211f38","metadata":{},"outputs":[],"source":["If we iterate through the list, each element corresponds to a row in the table:\n"]},{"cell_type":"code","id":"f00cc0d6-e600-4e01-b1c5-795ee1b67804","metadata":{},"outputs":[],"source":["for i,row in enumerate(table_rows):\n    print(\"row\",i,\"is\",row)\n    "]},{"cell_type":"markdown","id":"5ebf6cb5-652f-47ed-ac9e-6a52f0270bbc","metadata":{},"outputs":[],"source":["As \u003ccode\u003erow\u003c/code\u003e is a \u003ccode\u003ecell\u003c/code\u003e object, we can apply the method \u003ccode\u003efind_all\u003c/code\u003e to it and extract table cells in the object \u003ccode\u003ecells\u003c/code\u003e using the tag \u003ccode\u003etd\u003c/code\u003e, this is all the children with the name \u003ccode\u003etd\u003c/code\u003e. The result is a list, each element corresponds to a cell and is a \u003ccode\u003eTag\u003c/code\u003e object, we can iterate through this list as well. We can extract the content using the \u003ccode\u003estring\u003c/code\u003e attribute.\n"]},{"cell_type":"code","id":"32878dff-acd7-4e85-a3ee-0450f691df0f","metadata":{},"outputs":[],"source":["for i,row in enumerate(table_rows):\n    print(\"row\",i)\n    cells=row.find_all('td')\n    for j,cell in enumerate(cells):\n        print('colunm',j,\"cell\",cell)"]},{"cell_type":"markdown","id":"22e56f75-3cdf-4df7-a617-b65df9c9a380","metadata":{},"outputs":[],"source":["If we use a list we can match against any item in that list.\n"]},{"cell_type":"code","id":"d77c24bd-d9dd-4c48-ada7-995c7888765c","metadata":{},"outputs":[],"source":["list_input=table_bs .find_all(name=[\"tr\", \"td\"])\nlist_input"]},{"cell_type":"markdown","id":"3d19ed0d-e1e5-495b-97d4-39873d91577f","metadata":{},"outputs":[],"source":["### Attributes\n"]},{"cell_type":"markdown","id":"f1a2b1d2-daac-48a3-b27f-710ac1db020d","metadata":{},"outputs":[],"source":["If the argument is not recognized it will be turned into a filter on the tag's attributes. For example with the \u003ccode\u003eid\u003c/code\u003e argument, Beautiful Soup will filter against each tag's \u003ccode\u003eid\u003c/code\u003e attribute. For example, the first \u003ccode\u003etd\u003c/code\u003e elements have a value of \u003ccode\u003eid\u003c/code\u003e of \u003ccode\u003eflight\u003c/code\u003e, therefore we can filter based on that \u003ccode\u003eid\u003c/code\u003e value.\n"]},{"cell_type":"code","id":"432269b4-4247-4a57-be16-d5ffb5a1df84","metadata":{},"outputs":[],"source":["table_bs.find_all(id=\"flight\")"]},{"cell_type":"markdown","id":"f085cd43-7b3b-40f0-b3db-21a852c6fe75","metadata":{},"outputs":[],"source":["We can find all the elements that have links to the Florida Wikipedia page:\n"]},{"cell_type":"code","id":"570b298c-b955-4ffa-9f62-f4325b59a69b","metadata":{},"outputs":[],"source":["list_input=table_bs.find_all(href=\"https://en.wikipedia.org/wiki/Florida\")\nlist_input"]},{"cell_type":"markdown","id":"c0a1cdd5-8e06-420f-9ecb-a966e164d2ad","metadata":{},"outputs":[],"source":["If we set the \u003ccode\u003ehref\u003c/code\u003e attribute to True, regardless of what the value is, the code finds all tags with \u003ccode\u003ehref\u003c/code\u003e value:\n"]},{"cell_type":"code","id":"7947bc41-1d2d-46a3-bf74-d15289a167b6","metadata":{},"outputs":[],"source":["table_bs.find_all(href=True)"]},{"cell_type":"markdown","id":"86fa22e9-f94b-400d-b37c-d04b9f9985ed","metadata":{},"outputs":[],"source":["There are other methods for dealing with attributes and other related methods. Check out the following \u003ca href='https://www.crummy.com/software/BeautifulSoup/bs4/doc/?utm_medium=Exinfluencer\u0026utm_source=Exinfluencer\u0026utm_content=000026UJ\u0026utm_term=10006555\u0026utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkPY0101ENSkillsNetwork19487395-2021-01-01#css-selectors'\u003elink\u003c/a\u003e\n"]},{"cell_type":"markdown","id":"0e2a5300-23ec-42e1-b09e-525cd48415c9","metadata":{},"outputs":[],"source":["\u003ch3 id=\"exer_type\"\u003eExercise: \u003ccode\u003efind_all\u003c/code\u003e\u003c/h3\u003e\n"]},{"cell_type":"markdown","id":"b7889a6d-4809-470b-b3c5-9666988efe5e","metadata":{},"outputs":[],"source":["Using the logic above, find all the elements without \u003ccode\u003ehref\u003c/code\u003e value\n"]},{"cell_type":"code","id":"1b9d3f37-6aac-4126-bca5-cff78e5675f4","metadata":{},"outputs":[],"source":[""]},{"cell_type":"markdown","id":"c07eb27e-1548-42d1-9d1a-ed7483d08b03","metadata":{},"outputs":[],"source":["\u003cdetails\u003e\u003csummary\u003eClick here for the solution\u003c/summary\u003e\n","\n","```\n","table_bs.find_all(href=False)\n","\n","```\n","\n","\u003c/details\u003e\n"]},{"cell_type":"markdown","id":"869dd3e9-7d29-433f-a0f8-005ee08544d0","metadata":{},"outputs":[],"source":["Using the soup object \u003ccode\u003esoup\u003c/code\u003e, find the element with the \u003ccode\u003eid\u003c/code\u003e attribute content set to \u003ccode\u003e\"boldest\"\u003c/code\u003e.\n"]},{"cell_type":"code","id":"9c4ee6f5-5666-43fd-a1c7-3176e3844756","metadata":{},"outputs":[],"source":[""]},{"cell_type":"markdown","id":"1fffcc74-0e8d-40c1-9292-9f9cbedf0838","metadata":{},"outputs":[],"source":["\u003cdetails\u003e\u003csummary\u003eClick here for the solution\u003c/summary\u003e\n","\n","```\n","soup.find_all(id=\"boldest\")\n","\n","```\n","\n","\u003c/details\u003e\n"]},{"cell_type":"markdown","id":"0c3aa704-ca52-4b44-9bb9-ccaac281ef13","metadata":{},"outputs":[],"source":["### string\n"]},{"cell_type":"markdown","id":"e1c9539d-9c2b-431e-ad5f-3de52e0dfb51","metadata":{},"outputs":[],"source":["With string you can search for strings instead of tags, where we find all the elments with Florida:\n"]},{"cell_type":"code","id":"15b8dc84-e072-42ba-acdf-48784551f80e","metadata":{},"outputs":[],"source":["table_bs.find_all(string=\"Florida\")"]},{"cell_type":"markdown","id":"eb92da7f-8a50-4a09-8ccf-b5009aa834c0","metadata":{},"outputs":[],"source":["## find\n"]},{"cell_type":"markdown","id":"711c8beb-cdef-4326-8305-b35f4f8ad5c0","metadata":{},"outputs":[],"source":["The \u003ccode\u003efind_all()\u003c/code\u003e method scans the entire document looking for results. It’s useful if you are looking for one element, as you can use the \u003ccode\u003efind()\u003c/code\u003e method to find the first element in the document. Consider the following two tables:\n"]},{"cell_type":"code","id":"ec8f4a51-d74b-404a-8ce2-3e92d8a678dd","metadata":{},"outputs":[],"source":["%%html\n\u003ch3\u003eRocket Launch \u003c/h3\u003e\n\n\u003cp\u003e\n\u003ctable class='rocket'\u003e\n  \u003ctr\u003e\n    \u003ctd\u003eFlight No\u003c/td\u003e\n    \u003ctd\u003eLaunch site\u003c/td\u003e \n    \u003ctd\u003ePayload mass\u003c/td\u003e\n  \u003c/tr\u003e\n  \u003ctr\u003e\n    \u003ctd\u003e1\u003c/td\u003e\n    \u003ctd\u003eFlorida\u003c/td\u003e\n    \u003ctd\u003e300 kg\u003c/td\u003e\n  \u003c/tr\u003e\n  \u003ctr\u003e\n    \u003ctd\u003e2\u003c/td\u003e\n    \u003ctd\u003eTexas\u003c/td\u003e\n    \u003ctd\u003e94 kg\u003c/td\u003e\n  \u003c/tr\u003e\n  \u003ctr\u003e\n    \u003ctd\u003e3\u003c/td\u003e\n    \u003ctd\u003eFlorida \u003c/td\u003e\n    \u003ctd\u003e80 kg\u003c/td\u003e\n  \u003c/tr\u003e\n\u003c/table\u003e\n\u003c/p\u003e\n\u003cp\u003e\n\n\u003ch3\u003ePizza Party  \u003c/h3\u003e\n  \n    \n\u003ctable class='pizza'\u003e\n  \u003ctr\u003e\n    \u003ctd\u003ePizza Place\u003c/td\u003e\n    \u003ctd\u003eOrders\u003c/td\u003e \n    \u003ctd\u003eSlices \u003c/td\u003e\n   \u003c/tr\u003e\n  \u003ctr\u003e\n    \u003ctd\u003eDomino's Pizza\u003c/td\u003e\n    \u003ctd\u003e10\u003c/td\u003e\n    \u003ctd\u003e100\u003c/td\u003e\n  \u003c/tr\u003e\n  \u003ctr\u003e\n    \u003ctd\u003eLittle Caesars\u003c/td\u003e\n    \u003ctd\u003e12\u003c/td\u003e\n    \u003ctd \u003e144 \u003c/td\u003e\n  \u003c/tr\u003e\n  \u003ctr\u003e\n    \u003ctd\u003ePapa John's \u003c/td\u003e\n    \u003ctd\u003e15 \u003c/td\u003e\n    \u003ctd\u003e165\u003c/td\u003e\n  \u003c/tr\u003e\n"]},{"cell_type":"markdown","id":"26358b0e-3241-4ea9-a5f0-1f2b94ba3f33","metadata":{},"outputs":[],"source":["We store the HTML as a Python string and assign \u003ccode\u003etwo_tables\u003c/code\u003e:\n"]},{"cell_type":"code","id":"a4dde735-8119-4414-8826-e9102a4ce7bf","metadata":{},"outputs":[],"source":["two_tables=\"\u003ch3\u003eRocket Launch \u003c/h3\u003e\u003cp\u003e\u003ctable class='rocket'\u003e\u003ctr\u003e\u003ctd\u003eFlight No\u003c/td\u003e\u003ctd\u003eLaunch site\u003c/td\u003e \u003ctd\u003ePayload mass\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e1\u003c/td\u003e\u003ctd\u003eFlorida\u003c/td\u003e\u003ctd\u003e300 kg\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e2\u003c/td\u003e\u003ctd\u003eTexas\u003c/td\u003e\u003ctd\u003e94 kg\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e3\u003c/td\u003e\u003ctd\u003eFlorida \u003c/td\u003e\u003ctd\u003e80 kg\u003c/td\u003e\u003c/tr\u003e\u003c/table\u003e\u003c/p\u003e\u003cp\u003e\u003ch3\u003ePizza Party  \u003c/h3\u003e\u003ctable class='pizza'\u003e\u003ctr\u003e\u003ctd\u003ePizza Place\u003c/td\u003e\u003ctd\u003eOrders\u003c/td\u003e \u003ctd\u003eSlices \u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003eDomino's Pizza\u003c/td\u003e\u003ctd\u003e10\u003c/td\u003e\u003ctd\u003e100\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003eLittle Caesars\u003c/td\u003e\u003ctd\u003e12\u003c/td\u003e\u003ctd \u003e144 \u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003ePapa John's \u003c/td\u003e\u003ctd\u003e15 \u003c/td\u003e\u003ctd\u003e165\u003c/td\u003e\u003c/tr\u003e\""]},{"cell_type":"markdown","id":"c48c1237-3d32-47c5-aac6-b871c4248ea1","metadata":{},"outputs":[],"source":["We create a \u003ccode\u003eBeautifulSoup\u003c/code\u003e object  \u003ccode\u003etwo_tables_bs\u003c/code\u003e\n"]},{"cell_type":"code","id":"dce81816-e1ba-43f6-be38-bb2da850519c","metadata":{},"outputs":[],"source":["two_tables_bs= BeautifulSoup(two_tables, 'html.parser')"]},{"cell_type":"markdown","id":"bcfab311-1452-4047-ac00-727c5822f014","metadata":{},"outputs":[],"source":["We can find the first table using the tag name table\n"]},{"cell_type":"code","id":"5163611b-1c85-4dd2-9755-60a425f49aba","metadata":{},"outputs":[],"source":["two_tables_bs.find(\"table\")"]},{"cell_type":"markdown","id":"9d3f2f1b-1c95-448b-8d6d-9983dd674999","metadata":{},"outputs":[],"source":["We can filter on the class attribute to find the second table, but because class is a keyword in Python, we add an underscore to differentiate them.\n"]},{"cell_type":"code","id":"bd13ff13-15e4-43e2-ab9d-5568712c1dc4","metadata":{},"outputs":[],"source":["two_tables_bs.find(\"table\",class_='pizza')"]},{"cell_type":"markdown","id":"12927e50-5660-4013-a33b-3778f1003cd8","metadata":{},"outputs":[],"source":["\u003ch2 id=\"DSCW\"\u003eDownloading And Scraping The Contents Of A Web Page\u003c/h2\u003e \n"]},{"cell_type":"markdown","id":"cac77901-1b9a-48f2-a31e-f179554fbc3d","metadata":{},"outputs":[],"source":["We Download the contents of the web page:\n"]},{"cell_type":"code","id":"adcc5a78-5630-4c8d-99c4-37f33f22cb9e","metadata":{},"outputs":[],"source":["url = \"http://www.ibm.com\""]},{"cell_type":"markdown","id":"463f59ff-96b0-4e20-9922-9938241fefc3","metadata":{},"outputs":[],"source":["We use \u003ccode\u003eget\u003c/code\u003e to download the contents of the webpage in text format and store in a variable called \u003ccode\u003edata\u003c/code\u003e:\n"]},{"cell_type":"code","id":"e6eede6c-20b7-46aa-8b86-1f5aa21f3871","metadata":{},"outputs":[],"source":["data  = requests.get(url).text "]},{"cell_type":"markdown","id":"36e5214f-9b54-458d-96da-116e50a3808f","metadata":{},"outputs":[],"source":["We create a \u003ccode\u003eBeautifulSoup\u003c/code\u003e object using the \u003ccode\u003eBeautifulSoup\u003c/code\u003e constructor\n"]},{"cell_type":"code","id":"1e492a03-f519-4458-8f45-3581d99b93be","metadata":{},"outputs":[],"source":["soup = BeautifulSoup(data,\"html5lib\")  # create a soup object using the variable 'data'"]},{"cell_type":"markdown","id":"37ab294a-a581-427f-a483-140669c9365c","metadata":{},"outputs":[],"source":["Scrape all links\n"]},{"cell_type":"code","id":"10508361-be47-4853-8501-5364b92a22de","metadata":{},"outputs":[],"source":["for link in soup.find_all('a',href=True):  # in html anchor/link is represented by the tag \u003ca\u003e\n\n    print(link.get('href'))\n"]},{"cell_type":"markdown","id":"0fb6a580-9550-46de-8538-f29cdd8d454b","metadata":{},"outputs":[],"source":["### Scrape all images Tags\n"]},{"cell_type":"code","id":"26b41955-58d5-4440-abe7-390ce40eac8a","metadata":{},"outputs":[],"source":["for link in soup.find_all('img'):# in html image is represented by the tag \u003cimg\u003e\n    print(link)\n    print(link.get('src'))"]},{"cell_type":"markdown","id":"680fe490-51d8-41e2-9528-c603df60f2e0","metadata":{},"outputs":[],"source":["### Scrape data from HTML tables\n"]},{"cell_type":"code","id":"f97fde7a-b2e7-4eb1-9652-c13c7e225362","metadata":{},"outputs":[],"source":["#The below url contains an html table with data about colors and color codes.\nurl = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DA0321EN-SkillsNetwork/labs/datasets/HTMLColorCodes.html\""]},{"cell_type":"markdown","id":"b3a5a6ae-3c50-4b9b-b548-33bc7ea38c51","metadata":{},"outputs":[],"source":["Before proceeding to scrape a web site, you need to examine the contents and the way data is organized on the website. Open the above url in your browser and check how many rows and columns there are in the color table.\n"]},{"cell_type":"code","id":"8ce68de6-afda-4b0d-ba77-edf6e39f32c1","metadata":{},"outputs":[],"source":["# get the contents of the webpage in text format and store in a variable called data\ndata  = requests.get(url).text"]},{"cell_type":"code","id":"e5870454-bab4-4a8c-ba42-7dcb6cff75c4","metadata":{},"outputs":[],"source":["soup = BeautifulSoup(data,\"html5lib\")"]},{"cell_type":"code","id":"44d1446d-da29-4308-b017-0a52f0598a93","metadata":{},"outputs":[],"source":["#find a html table in the web page\ntable = soup.find('table') # in html table is represented by the tag \u003ctable\u003e"]},{"cell_type":"code","id":"480083b6-a5f4-4d1b-b02b-6f77ea4760c7","metadata":{},"outputs":[],"source":["#Get all rows from the table\nfor row in table.find_all('tr'): # in html table row is represented by the tag \u003ctr\u003e\n    # Get all columns in each row.\n    cols = row.find_all('td') # in html a column is represented by the tag \u003ctd\u003e\n    color_name = cols[2].string # store the value in column 3 as color_name\n    color_code = cols[3].text # store the value in column 4 as color_code\n    print(\"{}---\u003e{}\".format(color_name,color_code))"]},{"cell_type":"markdown","id":"318af9c7-6f36-453e-b912-3e59eab797d7","metadata":{},"outputs":[],"source":["## Scraping tables from a Web page using Pandas\n"]},{"cell_type":"markdown","id":"ef0e6c22-5264-4c9c-9fd1-5053c52a80c3","metadata":{},"outputs":[],"source":["Particularly for extracting tabular data from a web page, you may also use the `read_html()` method of the Pandas library. \n"]},{"cell_type":"code","id":"27812e7d-97ba-4ac2-816d-85073798c90a","metadata":{},"outputs":[],"source":["#The below url contains an html table with data about colors and color codes.\nurl = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DA0321EN-SkillsNetwork/labs/datasets/HTMLColorCodes.html\""]},{"cell_type":"markdown","id":"67db0df5-de6f-4ccd-8aae-7d440753632b","metadata":{},"outputs":[],"source":["You may extract all the tables from the given webpage simply by using the following commands.\n"]},{"cell_type":"code","id":"4478581c-8245-4e76-9607-72b20b38cbf3","metadata":{},"outputs":[],"source":["import pandas as pd\n\ntables = pd.read_html(url)\ntables"]},{"cell_type":"markdown","id":"ed8eb3af-38d9-47f9-8dea-da02c65f453d","metadata":{},"outputs":[],"source":["`tables` is now a list of dataframes representing the tables from the web page, in the sequence of their appearance. In the current  URL, there is only a single table, so the same can be accessed as shown below.\n"]},{"cell_type":"code","id":"2e1e6f4d-dc23-4b9f-9012-d78843d6e76a","metadata":{},"outputs":[],"source":["tables[0]"]},{"cell_type":"markdown","id":"f3fea0e9-4074-4900-9dc6-48932e4325a9","metadata":{},"outputs":[],"source":["## Authors\n"]},{"cell_type":"markdown","id":"f831324c-8d79-4885-a6c2-133614977b82","metadata":{},"outputs":[],"source":["Ramesh Sannareddy\n"]},{"cell_type":"markdown","id":"67adaef3-64fd-47c7-a83d-4959943df6da","metadata":{},"outputs":[],"source":["### Other Contributors\n"]},{"cell_type":"markdown","id":"92e66d43-a71c-436f-8be6-ffc7e069047d","metadata":{},"outputs":[],"source":["Rav Ahuja\n","\n","Abhishek Gagneja\n"]},{"cell_type":"markdown","id":"91f228e5-a6b5-4b3e-8990-1b2f9b6777b8","metadata":{},"outputs":[],"source":["## Change Log\n"]},{"cell_type":"markdown","id":"88cb197f-504d-4291-996a-39d48234b53a","metadata":{},"outputs":[],"source":["| Date (YYYY-MM-DD) | Version | Changed By            |          Change Description         |\n","| ----------------- | ------- | ----------------------| ----------------------------------- |\n","| 2023-11-02 | 1.1 | Abhishek Gagneja | Updated instructions, added web scraping using Pandas |\n","| 2023-06-11        | 1.0     | Akansha Yadav         |   Spell check                       |\n","| 2020-10-17        | 0.1     | Joseph Santarcangelo  |  Created initial version of the lab |\n"]},{"cell_type":"markdown","id":"3c856391-6573-437d-a270-953eb01cd1da","metadata":{},"outputs":[],"source":["Copyright © 2023 IBM Corporation. This notebook and its source code are released under the terms of the [MIT License](https://cognitiveclass.ai/mit-license/?utm_medium=Exinfluencer\u0026utm_source=Exinfluencer\u0026utm_content=000026UJ\u0026utm_term=10006555\u0026utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkPY0101ENSkillsNetwork19487395-2021-01-01).\n"]}],"metadata":{"kernelspec":{"display_name":"Python","language":"python","name":"conda-env-python-py"},"language_info":{"name":""}},"nbformat":4,"nbformat_minor":4}